apache spark run
#Passwordless ssh already set up

#Master and nodes
sudo apt-get install default-jre
sudo apt-get install scala

wget https://downloads.apache.org/spark/spark-3.0.1/spark-3.0.1-bin-hadoop2.7.tgz
tar xvf spark-3.0.1-bin-hadoop2.7.tgz 
sudo mv spark-3.0.1-bin-hadoop2.7 /usr/local/spark

sudo vim ~/.bashrc
#add to bottom of bashrc
export PATH=$PATH:/usr/local/spark/bin
source ~/.bashrc

#on master
cd /usr/local/spark/conf
cp spark-env.sh.template spark-env.sh
sudo vim spark-env.sh

#add these lines
export SPARK_MASTER_HOST='10.11.12.1'
export JAVA_HOME=/usr/lib/jvm/java-11-openjdk-amd64

sudo cp slaves.template slaves

sudo vim slaves

#comment out localhost
#add
master
node1
node2

cd /usr/local/spark/
./sbin/start-all.sh
./sbin/stop-all.sh


#Setting up sparklyr
sudo apt-get install r-base-core
sudo apt-get install libcurl4-openssl-dev
sudo apt-get install libssl-dev
sudo apt-get install libxml2-dev

